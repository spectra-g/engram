diff --git a/Cargo.lock b/Cargo.lock
index eb9c3ac..27f3710 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -144,7 +144,7 @@ dependencies = [
 
 [[package]]
 name = "engram-core"
-version = "0.1.0"
+version = "0.2.6"
 dependencies = [
  "clap",
  "git2",
diff --git a/README.md b/README.md
index e804a6f..672de4d 100644
--- a/README.md
+++ b/README.md
@@ -2,7 +2,7 @@
 
 **The "Blast Radius" Detector for AI Agents.**
 
-Engram gives your AI agent (Claude, Cursor, etc.) the one thing it lacks: **Organizational Memory.**
+Engram gives your AI agent the one thing it lacks: **Organizational Memory.**
 
 By analyzing your git history and project notes, Engram predicts what will break *before* the AI writes a single line of code. It detects files that are secretly coupled, even if they don't import each other directly, preventing the "fix one thing, break another" cycle.
 
@@ -139,7 +139,7 @@ Search notes by content or file path, or list all project knowledge.
 Engram is designed to be low-latency and zero-config.
 
 1.  **Smart Indexing:** Engram scans your git history incrementally in the background. It automatically filters out "noise" (like `package-lock.json` or binary files) and tracks file renames to ensure the history is accurate.
-2.  **The Risk Algorithm:** We don't just count commits. Engram calculates a **Risk Score (0-1)** based on **Coupling** (frequency) and **Recency** (how lately it happened).
+2.  **The Risk Algorithm:** Engram calculates a **Risk Score (0-1)** based on **Coupling** (frequency) and **Recency** (how lately it happened).
 3.  **Context Injection:** Finally, it combines these insights with your stored notes and relevant test names, formatting them into a concise summary that fits perfectly within the AI's context window.
 
 ### Performance
@@ -148,91 +148,38 @@ Engram is designed to be low-latency and zero-config.
 -  **Warm path** (cached DB): < 200ms
 -  All data stored locally in `.engram/engram.db` at the repo root
 
-## Quick Install
+## Install
 
 ```bash
 npm install -g @spectra-g/engram-adapter
 ```
 
-That's it â€” the correct binary for your platform is installed automatically. Then configure your MCP client to use `engram-adapter` (see [Using with MCP Clients](#using-with-mcp-clients) below).
+The correct binary for your platform (macOS, Linux, Windows) is installed automatically.
 
-## Installation & Usage
+## Setup
 
-### Prerequisites
+Engram is an [MCP server](https://modelcontextprotocol.io/) and works with any MCP-compatible client. Below are two examples - refer to your client's documentation for specifics.
 
--  Node.js (18+)
--  Git repository
-
-### Install from npm (Recommended)
-
-```bash
-npm install -g @spectra-g/engram-adapter
-```
-
-### Build from Source
-
-Requires Rust (1.70+) in addition to Node.js.
+### Claude Code
 
 ```bash
-# Build the Rust core
-npm run build:core
-
-# Build the TypeScript adapter
-npm run build:adapter
-
-# Or build both
-npm run build:all
-
+claude mcp add --scope user --transport stdio engram -- npx -y @spectra-g/engram-adapter
 ```
 
-### Running Tests
-
-```bash
-# Run all tests (Rust + adapter + E2E)
-npm run test:all
-
-# Or run individually
-npm run test:core      # Rust unit tests
-npm run test:adapter   # TypeScript unit tests
-npm run test:e2e       # End-to-end integration tests
-
-```
+### Cursor
 
-### Using with MCP Clients
+Settings > General > MCP Servers > Add New MCP Server:
+- **Name:** `engram`
+- **Type:** `command`
+- **Command:** `npx -y @spectra-g/engram-adapter`
 
-#### 1. For Claude Code (CLI)
+### Other Clients
 
-If installed via npm (`npm install -g @spectra-g/engram-adapter`), add to your config (`~/.claude.json` on macOS):
+Engram is MCP client-agnostic. Any client that supports the stdio transport can connect. If you need help with a specific client, please [open an issue](https://github.com/spectra-g/engram/issues) or contribute a setup guide.
 
-```json
-{
-  "mcpServers": {
-    "engram": {
-      "command": "engram-adapter"
-    }
-  }
-}
-```
+### System Instruction (Recommended)
 
-If building from source, use the full path instead:
-
-```json
-{
-  "mcpServers": {
-    "engram": {
-      "command": "node",
-      "args": ["/path/to/engram/adapter/dist/index.js"],
-      "env": {
-        "ENGRAM_CORE_BINARY": "/path/to/engram/target/release/engram-core"
-      }
-    }
-  }
-}
-```
-To make the AI use Engram automatically, you must give it a "System Instruction."
-
-1. Open (or create) the file `CLAUDE.md` in your project root.
-2. Paste the following rule exactly:
+To make your AI use Engram automatically on every task, add this to your project rules file (`CLAUDE.md`, `.cursorrules`, etc.):
 
 ```markdown
 ## Engram Workflow Policy
@@ -248,84 +195,36 @@ You MUST follow this strictly sequential workflow for EVERY code modification re
 4.  **Fix/Refactor**: Proceed with the code changes.
 
 ### Phase 3: Knowledge Capture (MANDATORY END)
-5.  **Save Learnings**: Before finishing, ask: *"Did I discover a hidden dependency, a tricky bug cause, or an architectural quirk?"*
+5.  **Save Learnings**: Before finishing, ask: *"Would a future developer be **surprised** by something I discovered?"*
+    Save a note ONLY for **non-obvious** insights:
+    - Hidden coupling between files that don't import each other
+    - Surprising runtime behavior (e.g., "this function silently swallows errors")
+    - Architectural constraints not evident from the code (e.g., "must deploy X before Y")
+    - Environment-specific gotchas (e.g., "CI uses Node 18, which lacks this API")
+
+    Do NOT save notes for:
+    - Typo fixes, simple renames, or formatting changes
+    - Bug fixes with obvious causes (e.g., off-by-one, null check)
+    - Routine refactors where the code is self-explanatory
+    - Changes that are already well-documented in comments or commit messages
+
     - **IF YES**: You MUST use `save_project_note` to persist this context for future sessions.
     - **IF NO**: Proceed to completion.
 
 NEVER skip Step 1. NEVER skip Step 5 if valuable context was gained.
 ```
 
-Then restart Claude Code. The tools will be available to Claude.
-
-#### 2. For Cursor
-To get Engram running in Cursor, you can add it via the Cursor Settings. Here is how you do it:
-
-1. Open MCP Settings
-2. Open Cursor and go to Settings (the gear icon in the top right, or Cmd + Shift + J on macOS / Ctrl + Shift + J on Windows).
-3. Navigate to General > MCP Servers.
-4. Add the New Server
-5. Click on "+ Add New MCP Server" and fill in the details based on your config:
-   1. Name: `engram`
-   2. Type: `command`
-   3. Command: `engram-adapter`
-
-   If building from source, use the full path instead:
-   1. Name: `engram`
-   2. Type: `command`
-   3. Command: `ENGRAM_CORE_BINARY=/path/to/engram/target/release/engram-core node /path/to/engram/adapter/dist/index.js`
-
-To make the AI use Engram automatically, you must give it a "System Instruction."
-
-1. Create a file named `.cursorrules` in your project root.
-2. Paste the exact same text block shown above (from the Claude section) into this file.
-
-*Note: Without this file, the AI will likely be "lazy" and skip the analysis step to save time.*
-
-#### Other MCP Clients
+## Development
 
-Any MCP-compatible client can connect to the adapter over stdio:
-
-```javascript
-import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
-import { Client } from "@modelcontextprotocol/sdk/client/index.js";
-
-const client = new Client({ name: "my-client", version: "1.0.0" });
-const transport = new StdioClientTransport({
-  command: "node",
-  args: ["/path/to/engram/adapter/dist/index.js"],
-  env: {
-    ENGRAM_CORE_BINARY: "/path/to/engram/target/release/engram-core"
-  }
-});
+### Build from Source
 
-await client.connect(transport);
-const result = await client.callTool({
-  name: "get_impact_analysis",
-  arguments: { file_path: "src/Auth.ts", repo_root: "/path/to/repo" }
-});
+Requires Rust (1.70+) and Node.js (18+).
 
+```bash
+npm run build:all    # Build Rust core + TypeScript adapter
+npm run test:all     # Run all tests (Rust + adapter + E2E)
 ```
 
-## Development Status
-
-### Planned Future Work
-
--  Zombie process cleanup on adapter crash
--  LCOV / Full Code Coverage Integration (Deep validation)
--  Support for monorepos (multiple projects in one repo)
--  Configurable ignore patterns (custom lockfile/binary lists)
-
-## Testing Strategy
-
-The project uses a rigorous testing approach:
-
--  **Rust unit tests** - Test individual functions in isolation
--  **Adapter unit tests** - Mock the Rust binary, test TypeScript logic
--  **E2E tests** - Generate real git repositories with deterministic commit histories, run full analysis cycles
--  **Performance tests** - Confirm all flows work to max 200ms latency
-
-All tests run in CI via `npm run test:all`.
-
 ## Contributing
 
 We welcome bug reports and community fixes. Please note that by contributing to this repository, you grant spectra-g a perpetual, irrevocable license to include your changes in both the public source and the commercially licensed versions of the software.
diff --git a/adapter/src/formatter.ts b/adapter/src/formatter.ts
index 0bd2b40..c549975 100644
--- a/adapter/src/formatter.ts
+++ b/adapter/src/formatter.ts
@@ -1,4 +1,4 @@
-import type { AnalysisResponse, CoupledFile, RiskLevel, FormattedCoupledFile } from "./types.js";
+import type { AnalysisResponse, CoupledFile, RiskLevel, FormattedCoupledFile, TestInfo } from "./types.js";
 
 const DISPLAY_LIMIT = 5;
 
@@ -65,6 +65,20 @@ export function buildFileDetails(files: FormattedCoupledFile[]): string {
     .join("\n\n");
 }
 
+export function buildTestInfoSection(testInfo: TestInfo): string {
+  const lines: string[] = [];
+  if (testInfo.coverage_hint) {
+    lines.push(`Test coverage: ${testInfo.coverage_hint}`);
+  }
+  for (const tf of testInfo.test_files) {
+    lines.push(`  ${tf.path} (${tf.test_count} test${tf.test_count === 1 ? "" : "s"}):`);
+    for (const intent of tf.test_intents) {
+      lines.push(`    - ${intent.title}`);
+    }
+  }
+  return lines.join("\n");
+}
+
 /**
  * Formats raw analysis JSON into a human-readable + machine-parseable
  * response for the MCP tool call. Returns JSON text that contains
@@ -91,7 +105,11 @@ export function formatAnalysisResponse(response: AnalysisResponse): string {
 
   const summaryLine = buildSummaryLine(response.file_path, formattedFiles);
   const details = buildFileDetails(formattedFiles);
-  const summary = details ? `${summaryLine}\n\n${details}` : summaryLine;
+  let summary = details ? `${summaryLine}\n\n${details}` : summaryLine;
+
+  if (response.test_info) {
+    summary += `\n\n${buildTestInfoSection(response.test_info)}`;
+  }
 
   return JSON.stringify({
     summary,
diff --git a/adapter/src/types.ts b/adapter/src/types.ts
index 6bb74bb..ea5f10e 100644
--- a/adapter/src/types.ts
+++ b/adapter/src/types.ts
@@ -19,12 +19,24 @@ export interface CoupledFile {
   test_intents?: TestIntent[];
 }
 
+export interface DiscoveredTestFile {
+  path: string;
+  test_intents: TestIntent[];
+  test_count: number;
+}
+
+export interface TestInfo {
+  test_files: DiscoveredTestFile[];
+  coverage_hint?: string;
+}
+
 export interface AnalysisResponse {
   file_path: string;
   repo_root: string;
   coupled_files: CoupledFile[];
   commit_count: number;
   analysis_time_ms: number;
+  test_info?: TestInfo;
 }
 
 export interface AnalysisRequest {
diff --git a/adapter/tests/formatter.test.ts b/adapter/tests/formatter.test.ts
index b66bae8..4f5221c 100644
--- a/adapter/tests/formatter.test.ts
+++ b/adapter/tests/formatter.test.ts
@@ -1,6 +1,6 @@
 import { describe, it, expect } from "vitest";
-import { classifyRisk, describeFile, buildSummaryLine, buildFileDetails, formatAnalysisResponse } from "../src/formatter.js";
-import type { AnalysisResponse, CoupledFile, FormattedCoupledFile } from "../src/types.js";
+import { classifyRisk, describeFile, buildSummaryLine, buildFileDetails, buildTestInfoSection, formatAnalysisResponse } from "../src/formatter.js";
+import type { AnalysisResponse, CoupledFile, FormattedCoupledFile, TestInfo } from "../src/types.js";
 
 describe("classifyRisk", () => {
   it("should return Critical for scores >= 0.8", () => {
@@ -157,4 +157,94 @@ describe("formatAnalysisResponse", () => {
     expect(parsed.formatted_files[0].test_intents).toBeUndefined();
     expect(parsed.summary).not.toContain("Current test behavior");
   });
+
+  it("should include test_info section in summary when present", () => {
+    const response = makeResponse(1);
+    response.test_info = {
+      test_files: [
+        {
+          path: "src/__tests__/Auth.test.tsx",
+          test_intents: [
+            { title: "should login" },
+            { title: "should logout" },
+          ],
+          test_count: 2,
+        },
+      ],
+      coverage_hint: "2 tests covering a 100-line source file",
+    };
+    const parsed = JSON.parse(formatAnalysisResponse(response));
+
+    expect(parsed.summary).toContain("Test coverage: 2 tests covering a 100-line source file");
+    expect(parsed.summary).toContain("src/__tests__/Auth.test.tsx (2 tests):");
+    expect(parsed.summary).toContain("- should login");
+    expect(parsed.summary).toContain("- should logout");
+    expect(parsed.test_info).toBeDefined();
+  });
+
+  it("should not include test_info section when absent", () => {
+    const response = makeResponse(1);
+    const parsed = JSON.parse(formatAnalysisResponse(response));
+
+    expect(parsed.summary).not.toContain("Test coverage:");
+    expect(parsed.test_info).toBeUndefined();
+  });
+});
+
+describe("buildTestInfoSection", () => {
+  it("should render coverage hint and test files", () => {
+    const info: TestInfo = {
+      test_files: [
+        {
+          path: "src/Auth.test.tsx",
+          test_intents: [{ title: "should login" }],
+          test_count: 1,
+        },
+      ],
+      coverage_hint: "1 test covering a 50-line source file",
+    };
+    const section = buildTestInfoSection(info);
+    expect(section).toContain("Test coverage: 1 test covering a 50-line source file");
+    expect(section).toContain("src/Auth.test.tsx (1 test):");
+    expect(section).toContain("- should login");
+  });
+
+  it("should pluralize test count correctly", () => {
+    const info: TestInfo = {
+      test_files: [
+        {
+          path: "src/Auth.test.tsx",
+          test_intents: [{ title: "a" }, { title: "b" }],
+          test_count: 5,
+        },
+      ],
+    };
+    const section = buildTestInfoSection(info);
+    expect(section).toContain("(5 tests):");
+  });
+
+  it("should handle missing coverage_hint", () => {
+    const info: TestInfo = {
+      test_files: [
+        {
+          path: "src/Auth.test.tsx",
+          test_intents: [{ title: "should login" }],
+          test_count: 1,
+        },
+      ],
+    };
+    const section = buildTestInfoSection(info);
+    expect(section).not.toContain("Test coverage:");
+    expect(section).toContain("src/Auth.test.tsx (1 test):");
+  });
+
+  it("should handle empty test_files", () => {
+    const info: TestInfo = {
+      test_files: [],
+      coverage_hint: "0 tests covering a 100-line source file",
+    };
+    const section = buildTestInfoSection(info);
+    expect(section).toContain("Test coverage:");
+    expect(section).not.toContain("(");
+  });
 });
diff --git a/core/src/lib.rs b/core/src/lib.rs
index 2fab0e0..7f434e6 100644
--- a/core/src/lib.rs
+++ b/core/src/lib.rs
@@ -30,6 +30,7 @@ pub fn analyze(
     let mut response = temporal::analyze(repo_root, file_path, &db)?;
     knowledge::enrich_with_memories(&db, &mut response.coupled_files);
     test_intents::enrich_with_test_intents(repo_root, &mut response.coupled_files);
+    response.test_info = test_intents::discover_test_info(repo_root, file_path);
 
     // Record metrics (non-blocking - errors are logged but don't fail the analysis)
     if let Err(e) = metrics::record_analysis_event(&db, &response, &repo_root.to_string_lossy()) {
diff --git a/core/src/metrics.rs b/core/src/metrics.rs
index b3a2c9e..937da5b 100644
--- a/core/src/metrics.rs
+++ b/core/src/metrics.rs
@@ -128,6 +128,7 @@ mod tests {
             ],
             commit_count: 15,
             analysis_time_ms: 150,
+            test_info: None,
         };
 
         record_analysis_event(&db, &response, "/repo").unwrap();
@@ -183,6 +184,7 @@ mod tests {
             ],
             commit_count: 10,
             analysis_time_ms: 100,
+            test_info: None,
         };
 
         record_analysis_event(&db, &response, "/repo").unwrap();
@@ -238,6 +240,7 @@ mod tests {
             ],
             commit_count: 5,
             analysis_time_ms: 100,
+            test_info: None,
         };
 
         record_analysis_event(&db, &response, "/repo").unwrap();
@@ -257,6 +260,7 @@ mod tests {
             coupled_files: vec![],
             commit_count: 5,
             analysis_time_ms: 100,
+            test_info: None,
         };
 
         let response2 = AnalysisResponse {
@@ -265,6 +269,7 @@ mod tests {
             coupled_files: vec![],
             commit_count: 10,
             analysis_time_ms: 200,
+            test_info: None,
         };
 
         record_analysis_event(&db, &response1, "/repo1").unwrap();
@@ -290,6 +295,7 @@ mod tests {
                 coupled_files: vec![],
                 commit_count: 5,
                 analysis_time_ms: 100 + (i as u64 * 50),
+                test_info: None,
             };
             record_analysis_event(&db, &response, "/repo").unwrap();
         }
diff --git a/core/src/temporal.rs b/core/src/temporal.rs
index 3955aed..2984168 100644
--- a/core/src/temporal.rs
+++ b/core/src/temporal.rs
@@ -184,6 +184,7 @@ pub fn analyze(
         coupled_files,
         commit_count,
         analysis_time_ms: elapsed.as_millis() as u64,
+        test_info: None,
     })
 }
 
diff --git a/core/src/test_intents.rs b/core/src/test_intents.rs
index e349708..dc81a0b 100644
--- a/core/src/test_intents.rs
+++ b/core/src/test_intents.rs
@@ -3,7 +3,7 @@ use std::sync::LazyLock;
 
 use regex::Regex;
 
-use crate::types::{CoupledFile, TestIntent};
+use crate::types::{CoupledFile, DiscoveredTestFile, TestInfo, TestIntent};
 
 const MAX_INTENTS_PER_FILE: usize = 5;
 
@@ -24,6 +24,38 @@ static GO_TEST_RE: LazyLock<Regex> = LazyLock::new(|| {
     Regex::new(r"func\s+(Test\w+)\s*\(").unwrap()
 });
 
+/// Language classification for test regex selection.
+enum TestLang {
+    JsTs,
+    Rust,
+    Python,
+    Go,
+}
+
+/// Select the appropriate test language and regex for a file path.
+fn detect_test_language(path: &str) -> Option<(TestLang, &'static Regex)> {
+    let filename = Path::new(path)
+        .file_name()
+        .and_then(|f| f.to_str())
+        .unwrap_or("");
+
+    if filename.ends_with(".ts")
+        || filename.ends_with(".tsx")
+        || filename.ends_with(".js")
+        || filename.ends_with(".jsx")
+    {
+        Some((TestLang::JsTs, &JS_TEST_RE))
+    } else if filename.ends_with(".rs") || path.contains("/tests/") {
+        Some((TestLang::Rust, &RUST_TEST_RE))
+    } else if filename.ends_with(".py") {
+        Some((TestLang::Python, &PYTHON_TEST_RE))
+    } else if filename.ends_with(".go") {
+        Some((TestLang::Go, &GO_TEST_RE))
+    } else {
+        None
+    }
+}
+
 /// Check if a file path looks like a test file based on naming conventions.
 pub fn is_test_file(path: &str) -> bool {
     let Some(filename) = Path::new(path).file_name().and_then(|f| f.to_str()) else {
@@ -53,6 +85,16 @@ pub fn is_test_file(path: &str) -> bool {
         return true;
     }
 
+    // JS/TS: files inside a __tests__/ directory
+    if path.contains("__tests__/")
+        && (filename.ends_with(".ts")
+            || filename.ends_with(".tsx")
+            || filename.ends_with(".js")
+            || filename.ends_with(".jsx"))
+    {
+        return true;
+    }
+
     // Rust: files inside a /tests/ directory
     if path.contains("/tests/") && filename.ends_with(".rs") {
         return true;
@@ -74,58 +116,23 @@ fn humanize(name: &str) -> String {
 /// Extract test intent titles from file content using regex.
 /// Returns at most `MAX_INTENTS_PER_FILE` results.
 pub fn extract_test_intents(content: &str, path: &str) -> Vec<TestIntent> {
-    let filename = Path::new(path)
-        .file_name()
-        .and_then(|f| f.to_str())
-        .unwrap_or("");
+    let Some((lang, re)) = detect_test_language(path) else {
+        return Vec::new();
+    };
 
     let mut intents: Vec<TestIntent> = Vec::new();
 
-    if filename.ends_with(".ts")
-        || filename.ends_with(".tsx")
-        || filename.ends_with(".js")
-        || filename.ends_with(".jsx")
-    {
-        for cap in JS_TEST_RE.captures_iter(content) {
-            let title = cap.get(1).or_else(|| cap.get(2)).map(|m| m.as_str().to_string());
-            if let Some(t) = title {
-                intents.push(TestIntent { title: t });
-                if intents.len() >= MAX_INTENTS_PER_FILE {
-                    break;
-                }
-            }
-        }
-    } else if filename.ends_with(".rs") || path.contains("/tests/") {
-        for cap in RUST_TEST_RE.captures_iter(content) {
-            if let Some(name) = cap.get(1) {
-                intents.push(TestIntent {
-                    title: humanize(name.as_str()),
-                });
-                if intents.len() >= MAX_INTENTS_PER_FILE {
-                    break;
-                }
-            }
-        }
-    } else if filename.ends_with(".py") {
-        for cap in PYTHON_TEST_RE.captures_iter(content) {
-            if let Some(name) = cap.get(1) {
-                intents.push(TestIntent {
-                    title: humanize(name.as_str()),
-                });
-                if intents.len() >= MAX_INTENTS_PER_FILE {
-                    break;
-                }
-            }
-        }
-    } else if filename.ends_with(".go") {
-        for cap in GO_TEST_RE.captures_iter(content) {
-            if let Some(name) = cap.get(1) {
-                intents.push(TestIntent {
-                    title: humanize(name.as_str()),
-                });
-                if intents.len() >= MAX_INTENTS_PER_FILE {
-                    break;
-                }
+    for cap in re.captures_iter(content) {
+        let title = match lang {
+            // JS/TS uses two capture groups (single-quote and double-quote)
+            TestLang::JsTs => cap.get(1).or_else(|| cap.get(2)).map(|m| m.as_str().to_string()),
+            // All other languages use group 1 with humanized names
+            _ => cap.get(1).map(|m| humanize(m.as_str())),
+        };
+        if let Some(t) = title {
+            intents.push(TestIntent { title: t });
+            if intents.len() >= MAX_INTENTS_PER_FILE {
+                break;
             }
         }
     }
@@ -150,6 +157,119 @@ pub fn enrich_with_test_intents(repo_root: &Path, coupled_files: &mut [CoupledFi
     }
 }
 
+/// Find test files for a source file by naming convention, independent of git coupling.
+/// Checks candidate paths on disk and returns relative paths that exist.
+pub fn find_test_files(repo_root: &Path, source_path: &str) -> Vec<String> {
+    // Don't find tests for test files themselves
+    if is_test_file(source_path) {
+        return Vec::new();
+    }
+
+    let path = Path::new(source_path);
+    let parent = path.parent().unwrap_or(Path::new(""));
+    let Some(filename) = path.file_name().and_then(|f| f.to_str()) else {
+        return Vec::new();
+    };
+
+    let mut candidates: Vec<String> = Vec::new();
+
+    if let Some(stem) = filename.strip_suffix(".tsx")
+        .or_else(|| filename.strip_suffix(".ts"))
+        .or_else(|| filename.strip_suffix(".jsx"))
+        .or_else(|| filename.strip_suffix(".js"))
+    {
+        let exts = ["tsx", "ts", "jsx", "js"];
+        let tests_dir = parent.join("__tests__");
+        for ext in &exts {
+            candidates.push(parent.join(format!("{stem}.test.{ext}")).display().to_string());
+            candidates.push(parent.join(format!("{stem}.spec.{ext}")).display().to_string());
+            candidates.push(tests_dir.join(format!("{stem}.test.{ext}")).display().to_string());
+            candidates.push(tests_dir.join(format!("{stem}.spec.{ext}")).display().to_string());
+            candidates.push(tests_dir.join(format!("{stem}.{ext}")).display().to_string());
+        }
+    } else if let Some(stem) = filename.strip_suffix(".py") {
+        candidates.push(parent.join(format!("test_{stem}.py")).display().to_string());
+        candidates.push(parent.join(format!("{stem}_test.py")).display().to_string());
+        candidates.push(parent.join("tests").join(format!("test_{stem}.py")).display().to_string());
+    } else if let Some(stem) = filename.strip_suffix(".go") {
+        candidates.push(parent.join(format!("{stem}_test.go")).display().to_string());
+    } else if let Some(stem) = filename.strip_suffix(".rs") {
+        candidates.push(parent.join("tests").join(format!("{stem}.rs")).display().to_string());
+        // Crate-level tests directory
+        candidates.push(Path::new("tests").join(format!("{stem}.rs")).display().to_string());
+    }
+
+    // Deduplicate and check which candidates exist on disk
+    let mut found: Vec<String> = Vec::new();
+    let mut seen = std::collections::HashSet::new();
+    for candidate in &candidates {
+        if !seen.insert(candidate.clone()) {
+            continue;
+        }
+        if repo_root.join(candidate).is_file() {
+            found.push(candidate.clone());
+        }
+    }
+
+    found
+}
+
+/// Count the total number of test cases in file content (no cap).
+pub fn count_test_cases(content: &str, path: &str) -> u32 {
+    detect_test_language(path)
+        .map(|(_, re)| re.captures_iter(content).count() as u32)
+        .unwrap_or(0)
+}
+
+/// Discover test files for a source file and build a TestInfo with coverage hint.
+pub fn discover_test_info(repo_root: &Path, source_path: &str) -> Option<TestInfo> {
+    let test_paths = find_test_files(repo_root, source_path);
+    if test_paths.is_empty() {
+        return None;
+    }
+
+    let mut test_files: Vec<DiscoveredTestFile> = Vec::new();
+    let mut total_tests: u32 = 0;
+
+    for test_path in &test_paths {
+        let full_path = repo_root.join(test_path);
+        let Ok(content) = std::fs::read_to_string(&full_path) else {
+            continue;
+        };
+
+        let test_count = count_test_cases(&content, test_path);
+        let intents = extract_test_intents(&content, test_path);
+        total_tests += test_count;
+
+        test_files.push(DiscoveredTestFile {
+            path: test_path.clone(),
+            test_intents: intents,
+            test_count,
+        });
+    }
+
+    if test_files.is_empty() {
+        return None;
+    }
+
+    // Build coverage hint based on source file line count
+    let source_full = repo_root.join(source_path);
+    let coverage_hint = std::fs::read_to_string(&source_full)
+        .ok()
+        .map(|content| {
+            let line_count = content.lines().count();
+            format!(
+                "{total_tests} test{} covering a {line_count}-line source file",
+                if total_tests == 1 { "" } else { "s" },
+            )
+        });
+
+    Some(TestInfo {
+        test_files,
+        coverage_hint,
+    })
+}
+
 #[cfg(test)]
 mod tests {
     use super::*;
@@ -357,4 +477,333 @@ describe("Auth", () => {
         enrich_with_test_intents(tmp.path(), &mut files);
         assert!(files[0].test_intents.is_empty());
     }
+
+    // --- is_test_file __tests__/ tests ---
+
+    #[test]
+    fn test_detects_js_ts_in_dunder_tests_dir() {
+        assert!(is_test_file("src/__tests__/Auth.tsx"));
+        assert!(is_test_file("src/__tests__/Auth.ts"));
+        assert!(is_test_file("src/__tests__/Auth.test.tsx"));
+        assert!(is_test_file("src/components/__tests__/Button.jsx"));
+    }
+
+    #[test]
+    fn test_rejects_non_js_in_dunder_tests_dir() {
+        // A .py file inside __tests__/ should not match via JS rule
+        // (it should only match via Python rules)
+        assert!(!is_test_file("src/__tests__/readme.md"));
+    }
+
+    // --- find_test_files tests ---
+
+    #[test]
+    fn test_find_colocated_test_tsx() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        fs::create_dir_all(&src).unwrap();
+        fs::write(src.join("Auth.tsx"), "export class Auth {}").unwrap();
+        fs::write(src.join("Auth.test.tsx"), "it('works', () => {})").unwrap();
+
+        let found = find_test_files(tmp.path(), "src/Auth.tsx");
+        assert_eq!(found, vec!["src/Auth.test.tsx"]);
+    }
+
+    #[test]
+    fn test_find_dunder_tests_dir() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        let tests = tmp.path().join("src/__tests__");
+        fs::create_dir_all(&src).unwrap();
+        fs::create_dir_all(&tests).unwrap();
+        fs::write(src.join("Auth.tsx"), "export class Auth {}").unwrap();
+        fs::write(tests.join("Auth.test.tsx"), "it('works', () => {})").unwrap();
+
+        let found = find_test_files(tmp.path(), "src/Auth.tsx");
+        assert_eq!(found, vec!["src/__tests__/Auth.test.tsx"]);
+    }
+
+    #[test]
+    fn test_find_spec_variant() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        fs::create_dir_all(&src).unwrap();
+        fs::write(src.join("Auth.tsx"), "export class Auth {}").unwrap();
+        fs::write(src.join("Auth.spec.tsx"), "it('works', () => {})").unwrap();
+
+        let found = find_test_files(tmp.path(), "src/Auth.tsx");
+        assert_eq!(found, vec!["src/Auth.spec.tsx"]);
+    }
+
+    #[test]
+    fn test_find_multiple_matches() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        let tests = tmp.path().join("src/__tests__");
+        fs::create_dir_all(&src).unwrap();
+        fs::create_dir_all(&tests).unwrap();
+        fs::write(src.join("Auth.tsx"), "export class Auth {}").unwrap();
+        fs::write(src.join("Auth.test.tsx"), "it('a', () => {})").unwrap();
+        fs::write(tests.join("Auth.test.tsx"), "it('b', () => {})").unwrap();
+
+        let found = find_test_files(tmp.path(), "src/Auth.tsx");
+        assert_eq!(found.len(), 2);
+        assert!(found.contains(&"src/Auth.test.tsx".to_string()));
+        assert!(found.contains(&"src/__tests__/Auth.test.tsx".to_string()));
+    }
+
+    #[test]
+    fn test_find_cross_extension() {
+        // Source is .tsx but test is .test.ts
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        fs::create_dir_all(&src).unwrap();
+        fs::write(src.join("Auth.tsx"), "export class Auth {}").unwrap();
+        fs::write(src.join("Auth.test.ts"), "it('works', () => {})").unwrap();
+
+        let found = find_test_files(tmp.path(), "src/Auth.tsx");
+        assert_eq!(found, vec!["src/Auth.test.ts"]);
+    }
+
+    #[test]
+    fn test_find_python_prefix() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        fs::create_dir_all(&src).unwrap();
+        fs::write(src.join("auth.py"), "class Auth: pass").unwrap();
+        fs::write(src.join("test_auth.py"), "def test_login(): pass").unwrap();
+
+        let found = find_test_files(tmp.path(), "src/auth.py");
+        assert_eq!(found, vec!["src/test_auth.py"]);
+    }
+
+    #[test]
+    fn test_find_python_suffix() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        fs::create_dir_all(&src).unwrap();
+        fs::write(src.join("auth.py"), "class Auth: pass").unwrap();
+        fs::write(src.join("auth_test.py"), "def test_login(): pass").unwrap();
+
+        let found = find_test_files(tmp.path(), "src/auth.py");
+        assert_eq!(found, vec!["src/auth_test.py"]);
+    }
+
+    #[test]
+    fn test_find_python_tests_dir() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        let tests = tmp.path().join("src/tests");
+        fs::create_dir_all(&src).unwrap();
+        fs::create_dir_all(&tests).unwrap();
+        fs::write(src.join("auth.py"), "class Auth: pass").unwrap();
+        fs::write(tests.join("test_auth.py"), "def test_login(): pass").unwrap();
+
+        let found = find_test_files(tmp.path(), "src/auth.py");
+        assert_eq!(found, vec!["src/tests/test_auth.py"]);
+    }
+
+    #[test]
+    fn test_find_go_test() {
+        let tmp = TempDir::new().unwrap();
+        let pkg = tmp.path().join("pkg/auth");
+        fs::create_dir_all(&pkg).unwrap();
+        fs::write(pkg.join("auth.go"), "package auth").unwrap();
+        fs::write(pkg.join("auth_test.go"), "func TestLogin(t *testing.T) {}").unwrap();
+
+        let found = find_test_files(tmp.path(), "pkg/auth/auth.go");
+        assert_eq!(found, vec!["pkg/auth/auth_test.go"]);
+    }
+
+    #[test]
+    fn test_find_rust_tests_dir() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        let tests = tmp.path().join("tests");
+        fs::create_dir_all(&src).unwrap();
+        fs::create_dir_all(&tests).unwrap();
+        fs::write(src.join("auth.rs"), "pub fn login() {}").unwrap();
+        fs::write(tests.join("auth.rs"), "#[test] fn test_login() {}").unwrap();
+
+        let found = find_test_files(tmp.path(), "src/auth.rs");
+        assert_eq!(found, vec!["tests/auth.rs"]);
+    }
+
+    #[test]
+    fn test_find_no_matches() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        fs::create_dir_all(&src).unwrap();
+        fs::write(src.join("Auth.tsx"), "export class Auth {}").unwrap();
+
+        let found = find_test_files(tmp.path(), "src/Auth.tsx");
+        assert!(found.is_empty());
+    }
+
+    #[test]
+    fn test_find_skips_test_of_test() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        fs::create_dir_all(&src).unwrap();
+        fs::write(src.join("Auth.test.tsx"), "it('works', () => {})").unwrap();
+
+        let found = find_test_files(tmp.path(), "src/Auth.test.tsx");
+        assert!(found.is_empty());
+    }
+
+    // --- count_test_cases tests ---
+
+    #[test]
+    fn test_count_uncapped() {
+        let content = r#"
+describe("Many tests", () => {
+  it('test 1', () => {});
+  it('test 2', () => {});
+  it('test 3', () => {});
+  it('test 4', () => {});
+  it('test 5', () => {});
+  it('test 6', () => {});
+  it('test 7', () => {});
+});
+"#;
+        let count = count_test_cases(content, "src/Auth.test.ts");
+        assert_eq!(count, 7);
+    }
+
+    #[test]
+    fn test_count_python() {
+        let content = r#"
+def test_a(): pass
+def test_b(): pass
+def test_c(): pass
+def helper(): pass
+"#;
+        let count = count_test_cases(content, "test_foo.py");
+        assert_eq!(count, 3);
+    }
+
+    #[test]
+    fn test_count_go() {
+        let content = r#"
+func TestA(t *testing.T) {}
+func TestB(t *testing.T) {}
+func helper() {}
+"#;
+        let count = count_test_cases(content, "foo_test.go");
+        assert_eq!(count, 2);
+    }
+
+    #[test]
+    fn test_count_rust() {
+        let content = r#"
+#[test]
+fn test_a() {}
+#[test]
+fn test_b() {}
+fn helper() {}
+"#;
+        let count = count_test_cases(content, "tests/foo.rs");
+        assert_eq!(count, 2);
+    }
+
+    // --- discover_test_info tests ---
+
+    #[test]
+    fn test_discover_test_info_full() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        fs::create_dir_all(&src).unwrap();
+
+        // Source file: 10 lines
+        let source = "line1\nline2\nline3\nline4\nline5\nline6\nline7\nline8\nline9\nline10\n";
+        fs::write(src.join("Auth.tsx"), source).unwrap();
+
+        let test_content = r#"
+describe("Auth", () => {
+  it('should login', () => {});
+  it('should logout', () => {});
+  it('should refresh', () => {});
+});
+"#;
+        fs::write(src.join("Auth.test.tsx"), test_content).unwrap();
+
+        let info = discover_test_info(tmp.path(), "src/Auth.tsx");
+        assert!(info.is_some());
+        let info = info.unwrap();
+
+        assert_eq!(info.test_files.len(), 1);
+        assert_eq!(info.test_files[0].path, "src/Auth.test.tsx");
+        assert_eq!(info.test_files[0].test_count, 3);
+        assert_eq!(info.test_files[0].test_intents.len(), 3);
+
+        let hint = info.coverage_hint.unwrap();
+        assert!(hint.contains("3 tests"));
+        assert!(hint.contains("10-line source file"));
+    }
+
+    #[test]
+    fn test_discover_test_info_none_when_no_tests() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        fs::create_dir_all(&src).unwrap();
+        fs::write(src.join("Auth.tsx"), "export class Auth {}").unwrap();
+
+        let info = discover_test_info(tmp.path(), "src/Auth.tsx");
+        assert!(info.is_none());
+    }
+
+    #[test]
+    fn test_discover_test_info_singular() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        fs::create_dir_all(&src).unwrap();
+        fs::write(src.join("Auth.tsx"), "export class Auth {}").unwrap();
+
+        let test_content = "it('should login', () => {});";
+        fs::write(src.join("Auth.test.tsx"), test_content).unwrap();
+
+        let info = discover_test_info(tmp.path(), "src/Auth.tsx").unwrap();
+        let hint = info.coverage_hint.unwrap();
+        assert!(hint.contains("1 test covering"));
+    }
+
+    #[test]
+    fn test_count_unknown_extension() {
+        let count = count_test_cases("some content", "README.md");
+        assert_eq!(count, 0);
+    }
+
+    #[test]
+    fn test_count_empty_content() {
+        let count = count_test_cases("", "src/Auth.test.ts");
+        assert_eq!(count, 0);
+    }
+
+    #[test]
+    fn test_find_root_level_file() {
+        let tmp = TempDir::new().unwrap();
+        fs::write(tmp.path().join("auth.py"), "class Auth: pass").unwrap();
+        fs::write(tmp.path().join("test_auth.py"), "def test_login(): pass").unwrap();
+
+        let found = find_test_files(tmp.path(), "auth.py");
+        assert_eq!(found, vec!["test_auth.py"]);
+    }
+
+    #[test]
+    fn test_discover_test_info_empty_test_file() {
+        let tmp = TempDir::new().unwrap();
+        let src = tmp.path().join("src");
+        fs::create_dir_all(&src).unwrap();
+        fs::write(src.join("Auth.tsx"), "export class Auth {}").unwrap();
+        // Test file exists but contains no test cases
+        fs::write(src.join("Auth.test.tsx"), "// TODO: add tests").unwrap();
+
+        let info = discover_test_info(tmp.path(), "src/Auth.tsx");
+        assert!(info.is_some());
+        let info = info.unwrap();
+        assert_eq!(info.test_files[0].test_count, 0);
+        assert!(info.test_files[0].test_intents.is_empty());
+        let hint = info.coverage_hint.unwrap();
+        assert!(hint.contains("0 tests"));
+    }
 }
diff --git a/core/src/types.rs b/core/src/types.rs
index b7e91ae..1c356be 100644
--- a/core/src/types.rs
+++ b/core/src/types.rs
@@ -13,6 +13,22 @@ pub struct AnalysisResponse {
     pub coupled_files: Vec<CoupledFile>,
     pub commit_count: u32,
     pub analysis_time_ms: u64,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub test_info: Option<TestInfo>,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct DiscoveredTestFile {
+    pub path: String,
+    pub test_intents: Vec<TestIntent>,
+    pub test_count: u32,
+}
+
+#[derive(Debug, Clone, Serialize, Deserialize)]
+pub struct TestInfo {
+    pub test_files: Vec<DiscoveredTestFile>,
+    #[serde(skip_serializing_if = "Option::is_none")]
+    pub coverage_hint: Option<String>,
 }
 
 #[derive(Debug, Clone, Serialize, Deserialize)]
diff --git a/e2e/tests/test-intents.test.ts b/e2e/tests/test-intents.test.ts
index a4ccaa1..15535f0 100644
--- a/e2e/tests/test-intents.test.ts
+++ b/e2e/tests/test-intents.test.ts
@@ -1,6 +1,6 @@
 import { describe, it, expect, beforeAll, afterAll } from "vitest";
 import { McpTestClient } from "./helpers/mcp-client.js";
-import { createTestIntentsRepo } from "../../fixtures/src/scenarios/test-intents.js";
+import { createTestIntentsRepo, createDunderTestsRepo } from "../../fixtures/src/scenarios/test-intents.js";
 import { CORE_BINARY_PATH } from "./setup.js";
 import { rmSync } from "node:fs";
 
@@ -81,3 +81,66 @@ describe("test-intents: test intent extraction", () => {
     expect(testFile.test_intents.length).toBeLessThanOrEqual(5);
   });
 });
+
+describe("test-intents: proactive test discovery via __tests__/", () => {
+  let client: McpTestClient;
+  let repoDir: string;
+
+  beforeAll(async () => {
+    repoDir = createDunderTestsRepo();
+    client = new McpTestClient();
+    await client.connect({ coreBinaryPath: CORE_BINARY_PATH });
+  });
+
+  afterAll(async () => {
+    await client.close();
+    rmSync(repoDir, { recursive: true, force: true });
+  });
+
+  it("should discover test files in __tests__/ via proactive discovery", async () => {
+    const result = await client.callTool("get_impact_analysis", {
+      file_path: "src/tools/base64/Base64Tool.tsx",
+      repo_root: repoDir,
+    });
+
+    const data = JSON.parse(result.content[0].text!);
+
+    // test_info should discover the __tests__/ file via naming convention
+    expect(data.test_info).toBeDefined();
+    expect(data.test_info.test_files.length).toBeGreaterThan(0);
+
+    const discoveredTest = data.test_info.test_files.find(
+      (f: { path: string }) => f.path.includes("Base64Tool.test.tsx")
+    );
+    expect(discoveredTest).toBeDefined();
+    expect(discoveredTest.test_count).toBe(3);
+
+    const titles = discoveredTest.test_intents.map((t: { title: string }) => t.title);
+    expect(titles).toContain("should encode string to base64");
+    expect(titles).toContain("should decode base64 to string");
+  });
+
+  it("should include coverage hint in test_info", async () => {
+    const result = await client.callTool("get_impact_analysis", {
+      file_path: "src/tools/base64/Base64Tool.tsx",
+      repo_root: repoDir,
+    });
+
+    const data = JSON.parse(result.content[0].text!);
+    expect(data.test_info).toBeDefined();
+    expect(data.test_info.coverage_hint).toBeDefined();
+    expect(data.test_info.coverage_hint).toContain("3 tests");
+    expect(data.test_info.coverage_hint).toContain("source file");
+  });
+
+  it("should include test_info in summary output", async () => {
+    const result = await client.callTool("get_impact_analysis", {
+      file_path: "src/tools/base64/Base64Tool.tsx",
+      repo_root: repoDir,
+    });
+
+    const data = JSON.parse(result.content[0].text!);
+    expect(data.summary).toContain("Test coverage:");
+    expect(data.summary).toContain("3 tests");
+  });
+});
diff --git a/fixtures/src/scenarios/test-intents.ts b/fixtures/src/scenarios/test-intents.ts
index ca54e05..a8683da 100644
--- a/fixtures/src/scenarios/test-intents.ts
+++ b/fixtures/src/scenarios/test-intents.ts
@@ -80,3 +80,54 @@ describe('Auth', () => {
 
   return createRepo({ commits });
 }
+
+/**
+ * Creates a repo where the test file lives in __tests__/ and is NOT
+ * co-committed with the source file (so it won't appear in coupled_files).
+ * This tests proactive test discovery via find_test_files.
+ */
+export function createDunderTestsRepo(): string {
+  const testFileContent = `
+import { Base64 } from '../Base64Tool';
+
+describe('Base64Tool', () => {
+  it('should encode string to base64', () => {
+    expect(Base64.encode('hello')).toBe('aGVsbG8=');
+  });
+
+  it('should decode base64 to string', () => {
+    expect(Base64.decode('aGVsbG8=')).toBe('hello');
+  });
+
+  it('should handle empty input', () => {
+    expect(Base64.encode('')).toBe('');
+  });
+});
+`;
+
+  const commits: CommitSpec[] = [];
+
+  // Initial commit: source + test in __tests__/
+  commits.push({
+    files: {
+      "src/tools/base64/Base64Tool.tsx": "// Base64 module v0\nexport class Base64 {}",
+      "src/tools/base64/__tests__/Base64Tool.test.tsx": testFileContent,
+      "src/tools/base64/helpers.ts": "// helpers v0\nexport function pad() {}",
+    },
+    message: "initial commit",
+  });
+
+  // 10 commits changing ONLY source + helpers (NOT the test file)
+  // This ensures the test file won't appear in coupled_files
+  for (let i = 1; i <= 10; i++) {
+    commits.push({
+      files: {
+        "src/tools/base64/Base64Tool.tsx": `// Base64 module v${i}\nexport class Base64 { version = ${i}; }`,
+        "src/tools/base64/helpers.ts": `// helpers v${i}\nexport function pad() { return ${i}; }`,
+      },
+      message: `update base64 and helpers v${i}`,
+    });
+  }
+
+  return createRepo({ commits });
+}
